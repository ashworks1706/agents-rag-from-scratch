{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36be9c2",
   "metadata": {},
   "source": [
    "# Agents and RAG, A Technical Deep Dive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389560b9",
   "metadata": {},
   "source": [
    "In this notebook, i'll be using the Lang and Llama family for building and exploring RAG from scratch and the techniques we can do with Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedb5de",
   "metadata": {},
   "source": [
    "### Brief History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4eff09",
   "metadata": {},
   "source": [
    "The concept of intelligent agents has evolved dramatically over the past seven decades, transforming from simple rule-based systems to today's sophisticated AI companions that can reason, plan, and act autonomously. Understanding this progression is essential because it helps us appreciate why modern agentic systems represent such a significant breakthrough and why they're becoming central to how we build AI applications. The journey began in the 1950s when researchers like Allen Newell and Herbert Simon created the Logic Theorist, a program that could prove mathematical theorems by exploring different logical paths. These early agents were like skilled craftsmen—they could perform specific tasks very well, but only within narrow, pre-defined domains. The 1970s and 1980s brought expert systems like MYCIN for medical diagnosis and DENDRAL for chemical analysis. While impressive, these systems required months of manual knowledge engineering, where human experts had to explicitly encode their domain knowledge into rigid rule sets.\n",
    "\n",
    "The 1990s marked a shift toward more flexible software agents that could operate in networked environments and coordinate with other agents. This period introduced the concept of multi-agent systems, where multiple specialized agents could collaborate to solve complex problems. However, these systems still required extensive manual programming and could only handle situations their creators had anticipated. The real transformation began in the 2000s with machine learning advances. Agents could now learn from data rather than relying solely on hand-coded rules. Virtual assistants like Siri and Alexa brought agent technology to mainstream consumers, though they remained relatively narrow in scope—essentially sophisticated voice interfaces for search and simple task execution.\n",
    "\n",
    "<img src=\"https://miro.medium.com/1*Ygen57Qiyrc8DXAFsjZLNA.gif\" width=700>\n",
    "\n",
    "The breakthrough moment arrived with large language models starting around 2020. Systems like GPT-3 and GPT-4 combined vast knowledge with sophisticated reasoning abilities, creating agents that could understand natural language, maintain context across conversations, and tackle a wide variety of tasks without task-specific programming. Unlike their predecessors, these modern agents can break down complex problems into steps, use external tools when needed, and adapt to new situations they've never encountered before. This evolution represents a fundamental shift from automation to augmentation. Where early agents automated specific, predefined tasks, today's agents can understand our goals and work as collaborative partners in problem-solving. They can handle ambiguous instructions, incomplete information, and constantly changing contexts—capabilities that make them invaluable for building sophisticated applications like retrieval-augmented generation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0100815",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed0b4ae",
   "metadata": {},
   "source": [
    "When we talk about agents in 2025, we're entering a landscape where the term has become both ubiquitous and somewhat ambiguous. Different organizations and researchers use \"agent\" to describe everything from simple chatbots to fully autonomous systems that can operate independently for weeks. This diversity in definition isn't just academic—it reflects fundamentally different architectural approaches that will determine how we build the next generation of AI applications.\n",
    "\n",
    "<img src=\"https://substackcdn.com/image/fetch/$s_!A_Oy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3177e12-432e-4e41-814f-6febf7a35f68_1360x972.png\" width=700>\n",
    "\n",
    "At its core, an agent is a system that can perceive its environment, make decisions, and take actions to achieve specific goals. However, the way these capabilities are implemented varies dramatically. Some define agents as fully autonomous systems that operate independently over extended periods, using various tools and adapting their strategies based on feedback. Think of these like a personal assistant who can manage your entire schedule, book flights, handle emails, and make decisions on your behalf without constant supervision.\n",
    "\n",
    "Others use the term more broadly to describe any system that follows predefined workflows to accomplish tasks. These implementations are more like following a detailed recipe—each step is predetermined, and while the system can handle some variations, it operates within clearly defined boundaries. The distinction between these approaches is crucial because it affects everything from system reliability to development complexity.\n",
    "\n",
    "The most useful way to think about this spectrum is through the lens of control and decision-making. Workflows are systems where large language models and tools are orchestrated through predefined code paths. Every decision point is anticipated by the developer, and the system follows predetermined logic to handle different scenarios. Agents, in contrast, are systems where the LLM dynamically directs its own processes and tool usage, maintaining control over how it accomplishes tasks. The model itself decides what to do next, which tools to use, and how to adapt when things don't go as planned.\n",
    "\n",
    "#### Simplicity defines perfectionism not complexity\n",
    "\n",
    "\n",
    "When building applications with LLMs, the fundamental principle should be finding the simplest solution that meets your requirements. This might mean not building agentic systems at all. Agentic systems inherently trade latency and cost for better task performance, and you need to carefully consider when this tradeoff makes sense for your specific use case.\n",
    "\n",
    "When more complexity is warranted, workflows offer predictability and consistency for well-defined tasks where you can anticipate most scenarios and edge cases. They're excellent for standardized processes like data processing pipelines, content moderation, or structured analysis tasks. Agents become the better choice when you need flexibility and model-driven decision-making at scale—situations where the variety of inputs and required responses is too broad to predefine, or where the system needs to adapt to entirely new scenarios.\n",
    "\n",
    "The reality is that for many applications, the most effective approach involves optimizing single LLM calls with retrieval and in-context examples rather than building complex agentic systems. However, as we'll explore throughout this tutorial, there are compelling scenarios where the additional complexity of agents becomes not just beneficial, but necessary for achieving your goals. Understanding when and how to make this transition is what separates effective AI system builders from those who over-engineer solutions to problems that could be solved more simply.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6bd7ab",
   "metadata": {},
   "source": [
    "#### Prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb1b8e",
   "metadata": {},
   "source": [
    "Prompts are the fundamental interface between human intent and AI capabilities, serving as the bridge that translates our natural language requests into structured instructions that language models can understand and act upon. In the context of agentic systems, prompts become even more critical because they not only convey what we want the agent to accomplish, but also how the agent should approach problem-solving, what tools it can use, and how it should reason through complex tasks.\n",
    "\n",
    "Think of prompts as the instruction manual for your AI agent—just as a well-written manual can make the difference between a novice successfully assembling furniture or ending up with a pile of confused parts, a well-crafted prompt determines whether your agent performs brilliantly or struggles to understand your intent. The quality and structure of your prompts directly influence the agent's reasoning capabilities, tool usage patterns, and overall effectiveness in completing tasks.\n",
    "\n",
    "<img src=\"https://www.datablist.com/_next/image?url=%2Fhowto_images%2Fhow-to-write-prompt-ai-agents%2Fstructured-ai-agent-prompt.png&w=3840&q=75\" width=700>\n",
    "\n",
    "There are several types of prompts that serve different purposes in agentic systems. System prompts establish the agent's role, personality, and fundamental operating principles—these are like giving someone their job description and company handbook before they start work. User prompts contain the specific tasks or questions you want the agent to handle, while few-shot prompts provide examples of desired input-output patterns to guide the agent's responses. Chain-of-thought prompts encourage step-by-step reasoning, helping agents break down complex problems into manageable pieces.\n",
    "\n",
    "In multi-step agentic workflows, prompt engineering becomes particularly sophisticated because you need to design prompts that not only solve individual tasks but also coordinate between different stages of processing. The agent needs to understand when to use specific tools, how to interpret tool outputs, and how to maintain context across multiple interaction cycles. This requires careful consideration of prompt structure, token efficiency, and the logical flow of information through your system.\n",
    "\n",
    "Let's explore how to implement basic prompt templates using LangChain with Google's Gemini model to see these concepts in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "# Initialize Gemini model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.7,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# Basic prompt template example\n",
    "basic_template = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"audience\"],\n",
    "    template=\"\"\"\n",
    "    You are an expert educator who excels at explaining complex topics clearly.\n",
    "    \n",
    "    Topic: {topic}\n",
    "    Audience: {audience}\n",
    "    \n",
    "    Please provide a clear, engaging explanation of this topic that is appropriate \n",
    "    for the specified audience. Include relevant examples and analogies to make \n",
    "    the concept accessible.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create a simple chain\n",
    "basic_chain = basic_template | llm | StrOutputParser()\n",
    "\n",
    "# Test the basic template\n",
    "response = basic_chain.invoke({\n",
    "    \"topic\": \"machine learning\", \n",
    "    \"audience\": \"high school students\"\n",
    "})\n",
    "print(\"Basic Response:\", response[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat-based prompt template for more conversational interactions\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful AI assistant with expertise in technology and science. \n",
    "    You provide accurate, clear explanations and can engage in detailed discussions.\n",
    "    Always think step-by-step when solving problems and explain your reasoning.\"\"\"),\n",
    "    (\"human\", \"I need help understanding {concept}. Can you break it down for me?\"),\n",
    "    (\"ai\", \"I'd be happy to help explain {concept}! Let me break this down step by step.\"),\n",
    "    (\"human\", \"{user_question}\")\n",
    "])\n",
    "\n",
    "# Create chat chain using LangChain's Expression Language (LCEL)\n",
    "# This creates a composable pipeline: prompt -> model -> parser\n",
    "# The | operator chains components where output of one becomes input of the next\n",
    "chat_chain = chat_template | llm | StrOutputParser()\n",
    "\n",
    "# What makes this powerful:\n",
    "# 1. Declarative: Reads left-to-right like a data pipeline\n",
    "# 2. Composable: Each component is modular and reusable\n",
    "# 3. Streaming-ready: Automatically supports streaming responses\n",
    "# 4. Type-safe: LangChain validates component compatibility\n",
    "# 5. Async-compatible: Easy to convert to async execution\n",
    "\n",
    "# Test chat template\n",
    "chat_response = chat_chain.invoke({\n",
    "    \"concept\": \"neural networks\",\n",
    "    \"user_question\": \"How do they actually learn from data?\"\n",
    "})\n",
    "print(\"Chat Response:\", chat_response[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacbea9",
   "metadata": {},
   "source": [
    "Great! now our LLM can respond to our questions, but how can we tweak it more to determine how much it weighs the prompt guideline while responding with it's own knowledge and reasoning? let's see!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c858ca",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d7ff9",
   "metadata": {},
   "source": [
    "Hyperparameters are the control knobs that determine how a language model generates responses, acting like the settings on a sophisticated instrument that can dramatically change the output quality and behavior. Understanding these parameters is crucial for building effective agents because they directly influence how the model balances following prompt instructions versus drawing on its pre-trained knowledge, how creative or conservative its responses are, and how consistently it behaves across multiple interactions.\n",
    "\n",
    "The most fundamental hyperparameter is **temperature**, which controls the randomness in the model's token selection process. Think of temperature like adjusting the creativity dial on the model's brain—at low temperatures (0.0-0.3), the model becomes highly deterministic, almost always choosing the most probable next token, resulting in consistent but potentially repetitive responses. At moderate temperatures (0.7-1.0), the model introduces controlled randomness, allowing for more creative and varied outputs while maintaining coherence. At high temperatures (1.5+), the model becomes highly unpredictable, often producing creative but potentially nonsensical text.\n",
    "\n",
    "**Top-p (nucleus sampling)** works alongside temperature to refine token selection by considering only the smallest set of tokens whose cumulative probability exceeds the p threshold. For example, with top-p=0.9, the model only considers tokens that together account for 90% of the probability mass, effectively filtering out highly improbable options while maintaining diversity. This parameter is particularly important for maintaining quality while allowing creativity.\n",
    "\n",
    "**Top-k** sets a hard limit on the number of highest-probability tokens to consider at each step. Unlike top-p's dynamic approach, top-k provides a fixed constraint—if k=40, only the 40 most likely tokens are considered regardless of their probability distribution. This can be useful for maintaining consistency in specialized domains where vocabulary should be limited.\n",
    "\n",
    "**Max tokens** controls the maximum length of the generated response, serving as a computational and cost control mechanism. **Stop sequences** allow you to define specific strings that signal the model to cease generation, which is particularly useful in agentic workflows where you need precise control over output formatting.\n",
    "\n",
    "Let's explore how these parameters affect model behavior in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Configurations to demonstrate hyperparameter effects\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in exactly three sentences. Be creative but accurate.\"\n",
    ")\n",
    "\n",
    "# Low temperature - deterministic, consistent responses\n",
    "conservative_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.1,  # Very low temperature for consistency\n",
    "    max_tokens=150,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# Moderate temperature - balanced creativity and consistency  \n",
    "balanced_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.7,  # Standard temperature for most applications\n",
    "    max_tokens=150,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# High temperature - creative, varied responses\n",
    "creative_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=1.2,  # Higher temperature for creativity\n",
    "    max_tokens=150,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create chains for each configuration\n",
    "conservative_chain = prompt | conservative_llm | StrOutputParser()\n",
    "balanced_chain = prompt | balanced_llm | StrOutputParser()\n",
    "creative_chain = prompt | creative_llm | StrOutputParser()\n",
    "\n",
    "# Test the same prompt with different temperature settings\n",
    "topic = \"quantum computing\"\n",
    "\n",
    "print(\"=== CONSERVATIVE (Temperature=0.1) ===\")\n",
    "conservative_response = conservative_chain.invoke({\"topic\": topic})\n",
    "print(conservative_response)\n",
    "\n",
    "print(\"\\n=== BALANCED (Temperature=0.7) ===\")\n",
    "balanced_response = balanced_chain.invoke({\"topic\": topic})\n",
    "print(balanced_response)\n",
    "\n",
    "print(\"\\n=== CREATIVE (Temperature=1.2) ===\")\n",
    "creative_response = creative_chain.invoke({\"topic\": topic})\n",
    "print(creative_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  how hyperparameters affect prompt adherence vs. knowledge utilization\n",
    "instruction_following_prompt = PromptTemplate(\n",
    "    input_variables=[\"format\", \"content\"],\n",
    "    template=\"\"\"\n",
    "    You must follow this format EXACTLY: {format}\n",
    "    \n",
    "    Content to format: {content}\n",
    "    \n",
    "    Remember: Strict adherence to the format is required.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# High instruction-following (low temperature)\n",
    "strict_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.0,  # Maximum determinism for format adherence\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# More flexible interpretation (higher temperature)\n",
    "flexible_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\", \n",
    "    temperature=0.9,  # More creativity, less strict adherence\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "strict_chain = instruction_following_prompt | strict_llm | StrOutputParser()\n",
    "flexible_chain = instruction_following_prompt | flexible_llm | StrOutputParser()\n",
    "\n",
    "format_instruction = \"1. [Topic] 2. [Definition] 3. [Example]\"\n",
    "content = \"Machine learning algorithms that can improve automatically through experience\"\n",
    "\n",
    "print(\"=== STRICT ADHERENCE (Temperature=0.0) ===\")\n",
    "strict_result = strict_chain.invoke({\n",
    "    \"format\": format_instruction,\n",
    "    \"content\": content\n",
    "})\n",
    "print(strict_result)\n",
    "\n",
    "print(\"\\n=== FLEXIBLE INTERPRETATION (Temperature=0.9) ===\") \n",
    "flexible_result = flexible_chain.invoke({\n",
    "    \"format\": format_instruction,\n",
    "    \"content\": content\n",
    "})\n",
    "print(flexible_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347026a1",
   "metadata": {},
   "source": [
    "The examples above demonstrate how hyperparameters create a fundamental tradeoff between instruction following and creative knowledge application. Low temperature models excel at following precise formatting requirements and maintaining consistency across multiple calls, making them ideal for structured data extraction, API responses, and workflows where predictability is paramount. Higher temperature models bring more of the model's training knowledge into play, generating more diverse responses and creative solutions, but at the cost of strict instruction adherence.\n",
    "\n",
    "This balance becomes critical in agentic systems where you need to decide whether your agent should be a precise executor of specific instructions or a creative problem-solver that can adapt its approach based on context. The choice often depends on your use case: customer service bots might need low-temperature consistency, while creative writing assistants might benefit from higher-temperature diversity.\n",
    "\n",
    "Now that we understand how to control our model's behavior through prompts and hyperparameters, we need to give our agents the ability to extend beyond their base knowledge and interact with the world. This is where tools come into play - they're what transform a language model from a sophisticated text generator into an active agent that can perform real actions and access current information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df627673",
   "metadata": {},
   "source": [
    "### Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf486d",
   "metadata": {},
   "source": [
    "\n",
    "Tools are what transform language models from sophisticated text generators into active agents capable of performing real-world actions and accessing live information. Think of tools as the hands and senses of your AI agent - without them, even the most advanced language model is limited to working with only the knowledge it was trained on, which becomes stale the moment training ends. Tools bridge this gap by allowing agents to interact with databases, APIs, web services, file systems, and any other external systems your application needs to work with.\n",
    "\n",
    "<img src=\"https://media.licdn.com/dms/image/v2/D4D12AQGyFCaSY8w4Ag/article-cover_image-shrink_720_1280/B4DZYg8dDRHAAI-/0/1744309441965?e=1762992000&v=beta&t=NS3gCnYSTWkxVwnRpHX6tCG7wcXcGgEknNpowIVAo2k\" width=700>\n",
    "\n",
    "The fundamental concept behind tools in agentic systems is function calling (also known as tool calling). Modern language models like GPT-4, Claude, and Gemini have been specifically trained to understand when they need external information or capabilities, and can generate structured function calls with appropriate parameters. When an agent encounters a question about current weather, stock prices, or needs to perform calculations, it doesn't hallucinate an answer - instead, it recognizes the limitation and calls the appropriate tool.\n",
    "\n",
    "The tool execution process follows a predictable pattern: the agent receives a user request, analyzes what information or actions are needed, determines which tools to use, formats the tool calls with proper parameters, executes the tools, receives the results, and then synthesizes a response using both its knowledge and the tool outputs. This creates a powerful feedback loop where agents can chain multiple tool calls together, use the output of one tool as input to another, and dynamically adapt their approach based on intermediate results.\n",
    "\n",
    "There are three main categories of tools we'll explore: **built-in tools** that come pre-integrated with language model providers, **explicit tools** that you define and implement yourself, and **Model Context Protocol (MCP) tools** that provide standardized interfaces for complex integrations. Each category serves different purposes and offers varying levels of customization and complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55233785",
   "metadata": {},
   "source": [
    "#### Built-in Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b29da",
   "metadata": {},
   "source": [
    "\n",
    "Built-in tools are native capabilities provided directly by language model providers, eliminating the need for external integrations or custom implementations. Google's Gemini models, for example, come with several powerful built-in tools including Google Search integration, code execution capabilities, and mathematical computation tools. These tools are particularly valuable because they're optimized for the specific model, have minimal latency overhead, and don't require additional API keys or setup beyond your primary model access.\n",
    "\n",
    "The advantage of built-in tools is their seamless integration - the model provider handles all the complexity of tool execution, result formatting, and error handling. When you enable Google Search for Gemini, the model can perform web searches and incorporate real-time information directly into its responses without any additional code on your part. Similarly, the code execution tool allows Gemini to write and run Python code in a sandboxed environment, making it excellent for data analysis, mathematical calculations, and generating visualizations.\n",
    "\n",
    "Let's explore how to use Gemini's built-in tools with LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "# Initialize Gemini with built-in Google Search tool\n",
    "# The 'google_search_retrieval' tool allows the model to search the web for current information\n",
    "llm_with_search = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.3,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    # Enable Google Search integration - this gives the model access to real-time web information\n",
    "    tools=[\"google_search_retrieval\"]\n",
    ")\n",
    "\n",
    "# Create a prompt that would benefit from real-time information\n",
    "search_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can search for current information when needed.\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "search_chain = search_prompt | llm_with_search | StrOutputParser()\n",
    "\n",
    "# Test with a query that requires current information\n",
    "current_info_query = \"What are the latest developments in AI safety research in 2024?\"\n",
    "print(\"=== Query requiring current information ===\")\n",
    "search_response = search_chain.invoke({\"query\": current_info_query})\n",
    "print(search_response[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini with code execution capability\n",
    "# The 'code_execution' tool allows the model to write and run Python code\n",
    "llm_with_code = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.1,  # Lower temperature for more reliable code execution\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    # Enable code execution - model can write and run Python code in sandboxed environment\n",
    "    tools=[\"code_execution\"]\n",
    ")\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a data analyst assistant. When you need to perform calculations or data analysis, write and execute Python code.\"),\n",
    "    (\"human\", \"{analysis_request}\")\n",
    "])\n",
    "\n",
    "code_chain = code_prompt | llm_with_code | StrOutputParser()\n",
    "\n",
    "# Test with a request that benefits from code execution\n",
    "analysis_request = \"\"\"\n",
    "Analyze the following dataset and provide insights:\n",
    "Sales data: [120, 150, 180, 95, 200, 175, 160, 140, 190, 210]\n",
    "\n",
    "Calculate the mean, median, standard deviation, and identify any outliers.\n",
    "Create a simple visualization if possible.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Analysis with code execution ===\")\n",
    "code_response = code_chain.invoke({\"analysis_request\": analysis_request})\n",
    "print(code_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c82ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining multiple built-in tools for comprehensive analysis\n",
    "llm_with_multiple_tools = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.4,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    # Enable both search and code execution tools\n",
    "    tools=[\"google_search_retrieval\", \"code_execution\"]\n",
    ")\n",
    "\n",
    "comprehensive_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a research analyst assistant with access to both web search and code execution.\n",
    "    Use web search to find current information and code execution for any calculations or data analysis.\n",
    "    Always explain which tool you're using and why.\"\"\"),\n",
    "    (\"human\", \"{research_question}\")\n",
    "])\n",
    "\n",
    "comprehensive_chain = comprehensive_prompt | llm_with_multiple_tools | StrOutputParser()\n",
    "\n",
    "# Test with a complex query that benefits from both tools\n",
    "complex_query = \"\"\"\n",
    "Research the current market capitalization of the top 3 AI companies in 2024, \n",
    "then calculate what percentage each represents of the total combined market cap.\n",
    "Show your calculations step by step.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Research with multiple built-in tools ===\")\n",
    "comprehensive_response = comprehensive_chain.invoke({\"research_question\": complex_query})\n",
    "print(comprehensive_response[:800] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75c830",
   "metadata": {},
   "source": [
    "#### Explicit Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a351b4",
   "metadata": {},
   "source": [
    "While built-in tools provide excellent out-of-the-box functionality, the real power of agentic systems comes from creating custom tools tailored to your specific use case. Explicit tools are functions you define and implement yourself, giving agents the ability to interact with your databases, APIs, business logic, or any other systems your application requires. This is where agents transform from general-purpose assistants into specialized experts for your domain.\n",
    "\n",
    "The process of creating explicit tools involves defining the tool's interface (what parameters it accepts and what it returns), implementing the actual functionality, and then registering the tool with your agent framework. LangChain makes this process straightforward through its `@tool` decorator and `Tool` class, which handle the integration details while letting you focus on the business logic.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:2000/1*fu9Lu8D8DLnVFPAWg7N0jQ.png\" width=700>\n",
    "\n",
    "When designing explicit tools, it's important to think about granularity and composability. Rather than creating one massive tool that does everything, it's better to create focused tools that do one thing well and can be combined. For example, instead of a single \"manage_database\" tool, you might create separate \"query_user\", \"update_inventory\", and \"calculate_metrics\" tools that can work together.\n",
    "\n",
    "Let's explore how to create and use explicit tools with LangChain and Gemini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict\n",
    "import datetime\n",
    "\n",
    "# Define custom tools using the @tool decorator\n",
    "# This decorator automatically handles the tool registration and parameter validation\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str, country: str = \"US\") -> str:\n",
    "    \"\"\"\n",
    "    Get current weather information for a specified city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city to get weather for\n",
    "        country: The country code (default: US)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with weather information\n",
    "    \"\"\"\n",
    "    # Simulate weather API call - in practice, this would call a real weather service\n",
    "    weather_conditions = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\", \"partly cloudy\"]\n",
    "    temperature = random.randint(-10, 35)\n",
    "    condition = random.choice(weather_conditions)\n",
    "    \n",
    "    weather_data = {\n",
    "        \"city\": city,\n",
    "        \"country\": country,\n",
    "        \"temperature\": temperature,\n",
    "        \"condition\": condition,\n",
    "        \"humidity\": random.randint(30, 90),\n",
    "        \"timestamp\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return json.dumps(weather_data, indent=2)\n",
    "\n",
    "@tool\n",
    "def calculate_compound_interest(principal: float, rate: float, time: int, compounds_per_year: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Calculate compound interest for investment planning.\n",
    "    \n",
    "    Args:\n",
    "        principal: Initial investment amount\n",
    "        rate: Annual interest rate (as decimal, e.g., 0.05 for 5%)\n",
    "        time: Number of years\n",
    "        compounds_per_year: How many times interest compounds per year (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with calculation details\n",
    "    \"\"\"\n",
    "    # A = P(1 + r/n)^(nt)\n",
    "    amount = principal * (1 + rate/compounds_per_year) ** (compounds_per_year * time)\n",
    "    interest_earned = amount - principal\n",
    "    \n",
    "    result = {\n",
    "        \"principal\": principal,\n",
    "        \"annual_rate\": f\"{rate*100}%\",\n",
    "        \"time_years\": time,\n",
    "        \"compounds_per_year\": compounds_per_year,\n",
    "        \"final_amount\": round(amount, 2),\n",
    "        \"interest_earned\": round(interest_earned, 2),\n",
    "        \"total_return_percentage\": round((interest_earned/principal)*100, 2)\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "@tool  \n",
    "def search_user_database(query: str, user_type: str = \"all\") -> str:\n",
    "    \"\"\"\n",
    "    Search a simulated user database for customer information.\n",
    "    \n",
    "    Args:\n",
    "        query: Search term (name, email, or ID)\n",
    "        user_type: Filter by user type - \"premium\", \"basic\", or \"all\" (default)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with user information\n",
    "    \"\"\"\n",
    "    # Simulate database search - in practice, this would query your actual database\n",
    "    mock_users = [\n",
    "        {\"id\": \"001\", \"name\": \"Alice Johnson\", \"email\": \"alice@email.com\", \"type\": \"premium\", \"status\": \"active\"},\n",
    "        {\"id\": \"002\", \"name\": \"Bob Smith\", \"email\": \"bob@email.com\", \"type\": \"basic\", \"status\": \"active\"}, \n",
    "        {\"id\": \"003\", \"name\": \"Carol Davis\", \"email\": \"carol@email.com\", \"type\": \"premium\", \"status\": \"inactive\"},\n",
    "        {\"id\": \"004\", \"name\": \"David Wilson\", \"email\": \"david@email.com\", \"type\": \"basic\", \"status\": \"active\"}\n",
    "    ]\n",
    "    \n",
    "    # Filter by user type if specified\n",
    "    if user_type != \"all\":\n",
    "        mock_users = [user for user in mock_users if user[\"type\"] == user_type]\n",
    "    \n",
    "    # Search logic\n",
    "    results = []\n",
    "    query_lower = query.lower()\n",
    "    for user in mock_users:\n",
    "        if (query_lower in user[\"name\"].lower() or \n",
    "            query_lower in user[\"email\"].lower() or \n",
    "            query_lower == user[\"id\"]):\n",
    "            results.append(user)\n",
    "    \n",
    "    return json.dumps({\"query\": query, \"results\": results}, indent=2)\n",
    "\n",
    "# Collect all tools in a list\n",
    "custom_tools = [get_weather, calculate_compound_interest, search_user_database]\n",
    "\n",
    "print(\"=== Custom Tools Defined ===\")\n",
    "print(f\"Created {len(custom_tools)} custom tools:\")\n",
    "for tool in custom_tools:\n",
    "    print(f\"- {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080398ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent that can use our custom tools\n",
    "# We'll use Gemini as the underlying LLM with our custom tools\n",
    "\n",
    "# Initialize Gemini for tool calling\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.1,  # Lower temperature for more reliable tool usage\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create a prompt template for our tool-using agent\n",
    "tool_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant with access to several tools:\n",
    "    1. get_weather: Get current weather for any city\n",
    "    2. calculate_compound_interest: Calculate investment returns\n",
    "    3. search_user_database: Look up customer information\n",
    "    \n",
    "    Use these tools when needed to provide accurate, helpful responses.\n",
    "    Always explain which tool you're using and why.\n",
    "    If a tool returns JSON data, format it nicely for the user.\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "# Create the tool-calling agent\n",
    "# This agent will automatically decide when and how to use our custom tools\n",
    "agent = create_tool_calling_agent(llm, custom_tools, tool_prompt)\n",
    "\n",
    "# Create an agent executor to run the agent with tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, \n",
    "    tools=custom_tools, \n",
    "    verbose=True,  # Show the agent's thought process\n",
    "    handle_parsing_errors=True  # Gracefully handle any parsing issues\n",
    ")\n",
    "\n",
    "print(\"=== Tool-Using Agent Created ===\")\n",
    "print(\"Agent ready with custom tools integrated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c60256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with different types of requests\n",
    "\n",
    "print(\"=== Test 1: Weather Information ===\")\n",
    "weather_response = agent_executor.invoke({\n",
    "    \"input\": \"What's the weather like in Tokyo, Japan right now?\"\n",
    "})\n",
    "print(\"Response:\", weather_response['output'])\n",
    "\n",
    "print(\"\\n=== Test 2: Financial Calculation ===\")\n",
    "investment_response = agent_executor.invoke({\n",
    "    \"input\": \"If I invest $10,000 at 6% annual interest compounded monthly for 10 years, how much will I have?\"\n",
    "})\n",
    "print(\"Response:\", investment_response['output'])\n",
    "\n",
    "print(\"\\n=== Test 3: Database Search ===\")\n",
    "user_search_response = agent_executor.invoke({\n",
    "    \"input\": \"Can you find information about user Alice in our database?\"\n",
    "})\n",
    "print(\"Response:\", user_search_response['output'])\n",
    "\n",
    "print(\"\\n=== Test 4: Multi-tool Chain ===\")\n",
    "complex_response = agent_executor.invoke({\n",
    "    \"input\": \"\"\"I'm planning a trip to San Francisco and want to:\n",
    "    1. Check the weather there\n",
    "    2. Find any premium users in our database named David\n",
    "    3. Calculate how much $5000 invested at 4.5% annual interest for 5 years would grow to\n",
    "    \n",
    "    Please help with all three requests.\"\"\"\n",
    "})\n",
    "print(\"Response:\", complex_response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee3328",
   "metadata": {},
   "source": [
    "#### Model Context Protocol (MCP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c56fff",
   "metadata": {},
   "source": [
    "Model Context Protocol (MCP) represents the next evolution in AI tool integration, providing a standardized way for AI applications to securely connect to data sources and tools. Think of MCP as a universal translator that allows any AI system to communicate with any external service through a common protocol, eliminating the need for custom integrations for each tool or data source.\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/tweet_video_thumb/Gl7C44tXYAAdDSJ.jpg\" width=700>\n",
    "\n",
    "MCP was developed by Anthropic to solve the fragmentation problem in AI tool ecosystems. Before MCP, every AI application had to implement its own custom integrations for databases, APIs, file systems, and other external resources. This led to duplicated effort, security inconsistencies, and tools that only worked with specific AI platforms. MCP standardizes these interactions through a client-server architecture where MCP servers expose resources (like databases or file systems) and tools (like calculators or API clients) through a uniform interface.\n",
    "\n",
    "The protocol operates on JSON-RPC 2.0, enabling real-time, bidirectional communication between AI applications (MCP clients) and external resources (MCP servers). This means your agent can not only call tools but also receive real-time updates, notifications, and streaming data from external systems. The security model is built around explicit capability declarations and sandboxed execution, ensuring that agents can only access resources they've been explicitly granted permission to use.\n",
    "\n",
    "What makes MCP particularly powerful for RAG and agentic systems is its ability to provide **contextual data access**. Instead of just calling functions, MCP servers can expose rich contextual information about resources - like database schemas, file structures, or API capabilities - allowing agents to make more informed decisions about how to interact with external systems.\n",
    "\n",
    "Let's explore how to integrate MCP servers with LangChain and Gemini. For this example, we'll use the MCP SDK to create a simple server and then connect to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This example demonstrates MCP concepts. In practice, you would install:\n",
    "# pip install mcp langchain-mcp\n",
    "\n",
    "# For now, we'll simulate MCP functionality to understand the concepts\n",
    "from typing import Any, Dict, List\n",
    "import json\n",
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Simulate an MCP server interface\n",
    "@dataclass\n",
    "class MCPResource:\n",
    "    \"\"\"Represents a resource exposed by an MCP server\"\"\"\n",
    "    uri: str\n",
    "    name: str\n",
    "    description: str\n",
    "    mime_type: str\n",
    "\n",
    "@dataclass \n",
    "class MCPTool:\n",
    "    \"\"\"Represents a tool exposed by an MCP server\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: Dict[str, Any]\n",
    "\n",
    "class MockMCPServer:\n",
    "    \"\"\"Simulated MCP server for demonstration purposes\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.resources: List[MCPResource] = []\n",
    "        self.tools: List[MCPTool] = []\n",
    "        \n",
    "    def add_resource(self, resource: MCPResource):\n",
    "        self.resources.append(resource)\n",
    "        \n",
    "    def add_tool(self, tool: MCPTool):\n",
    "        self.tools.append(tool)\n",
    "        \n",
    "    def list_resources(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"List all available resources\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"uri\": r.uri,\n",
    "                \"name\": r.name, \n",
    "                \"description\": r.description,\n",
    "                \"mimeType\": r.mime_type\n",
    "            } for r in self.resources\n",
    "        ]\n",
    "        \n",
    "    def list_tools(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"List all available tools\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"name\": t.name,\n",
    "                \"description\": t.description,\n",
    "                \"inputSchema\": t.input_schema\n",
    "            } for t in self.tools\n",
    "        ]\n",
    "        \n",
    "    def read_resource(self, uri: str) -> str:\n",
    "        \"\"\"Read content from a resource\"\"\"\n",
    "        # Simulate resource reading\n",
    "        if \"customer_db\" in uri:\n",
    "            return json.dumps({\n",
    "                \"customers\": [\n",
    "                    {\"id\": 1, \"name\": \"John Doe\", \"email\": \"john@example.com\", \"tier\": \"gold\"},\n",
    "                    {\"id\": 2, \"name\": \"Jane Smith\", \"email\": \"jane@example.com\", \"tier\": \"silver\"}\n",
    "                ],\n",
    "                \"schema\": {\n",
    "                    \"id\": \"integer\",\n",
    "                    \"name\": \"string\", \n",
    "                    \"email\": \"string\",\n",
    "                    \"tier\": \"string\"\n",
    "                }\n",
    "            })\n",
    "        elif \"inventory\" in uri:\n",
    "            return json.dumps({\n",
    "                \"items\": [\n",
    "                    {\"sku\": \"A001\", \"name\": \"Laptop\", \"quantity\": 50, \"price\": 999.99},\n",
    "                    {\"sku\": \"A002\", \"name\": \"Mouse\", \"quantity\": 200, \"price\": 29.99}\n",
    "                ]\n",
    "            })\n",
    "        return \"Resource not found\"\n",
    "        \n",
    "    def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"Execute a tool with given arguments\"\"\"\n",
    "        if tool_name == \"query_analytics\":\n",
    "            metric = arguments.get(\"metric\", \"sales\")\n",
    "            period = arguments.get(\"period\", \"month\")\n",
    "            return json.dumps({\n",
    "                \"metric\": metric,\n",
    "                \"period\": period,\n",
    "                \"value\": 150000 if metric == \"sales\" else 1200,\n",
    "                \"trend\": \"increasing\",\n",
    "                \"timestamp\": \"2024-10-22T10:00:00Z\"\n",
    "            })\n",
    "        elif tool_name == \"send_notification\":\n",
    "            return json.dumps({\n",
    "                \"status\": \"sent\",\n",
    "                \"recipient\": arguments.get(\"recipient\"),\n",
    "                \"message\": arguments.get(\"message\"),\n",
    "                \"delivery_id\": \"notify_12345\"\n",
    "            })\n",
    "        return json.dumps({\"error\": \"Tool not found\"})\n",
    "\n",
    "# Create a mock MCP server with business resources and tools\n",
    "business_mcp = MockMCPServer(\"business_system\")\n",
    "\n",
    "# Add resources (data sources the agent can read)\n",
    "business_mcp.add_resource(MCPResource(\n",
    "    uri=\"mcp://business/customer_db\",\n",
    "    name=\"Customer Database\",\n",
    "    description=\"Customer information and account details\", \n",
    "    mime_type=\"application/json\"\n",
    "))\n",
    "\n",
    "business_mcp.add_resource(MCPResource(\n",
    "    uri=\"mcp://business/inventory\",\n",
    "    name=\"Inventory System\", \n",
    "    description=\"Product inventory and stock levels\",\n",
    "    mime_type=\"application/json\"\n",
    "))\n",
    "\n",
    "# Add tools (actions the agent can perform)\n",
    "business_mcp.add_tool(MCPTool(\n",
    "    name=\"query_analytics\",\n",
    "    description=\"Query business analytics and metrics\",\n",
    "    input_schema={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"metric\": {\"type\": \"string\", \"enum\": [\"sales\", \"users\", \"revenue\"]},\n",
    "            \"period\": {\"type\": \"string\", \"enum\": [\"day\", \"week\", \"month\", \"year\"]}\n",
    "        },\n",
    "        \"required\": [\"metric\"]\n",
    "    }\n",
    "))\n",
    "\n",
    "business_mcp.add_tool(MCPTool(\n",
    "    name=\"send_notification\", \n",
    "    description=\"Send notifications to users or systems\",\n",
    "    input_schema={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"recipient\": {\"type\": \"string\"},\n",
    "            \"message\": {\"type\": \"string\"},\n",
    "            \"priority\": {\"type\": \"string\", \"enum\": [\"low\", \"medium\", \"high\"]}\n",
    "        },\n",
    "        \"required\": [\"recipient\", \"message\"]\n",
    "    }\n",
    "))\n",
    "\n",
    "print(\"=== MCP Server Created ===\")\n",
    "print(f\"Server: {business_mcp.name}\")\n",
    "print(f\"Resources: {len(business_mcp.resources)}\")\n",
    "print(f\"Tools: {len(business_mcp.tools)}\")\n",
    "\n",
    "# List available resources and tools\n",
    "print(\"\\n=== Available Resources ===\")\n",
    "for resource in business_mcp.list_resources():\n",
    "    print(f\"- {resource['name']}: {resource['description']}\")\n",
    "    \n",
    "print(\"\\n=== Available Tools ===\") \n",
    "for tool in business_mcp.list_tools():\n",
    "    print(f\"- {tool['name']}: {tool['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangChain tools that interface with our MCP server\n",
    "# This demonstrates how MCP servers can be integrated into LangChain workflows\n",
    "\n",
    "@tool\n",
    "def mcp_read_resource(resource_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Read data from MCP server resources like databases or file systems.\n",
    "    \n",
    "    Args:\n",
    "        resource_name: Name of the resource to read (customer_db, inventory)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with resource data\n",
    "    \"\"\"\n",
    "    uri_map = {\n",
    "        \"customer_db\": \"mcp://business/customer_db\",\n",
    "        \"customers\": \"mcp://business/customer_db\", \n",
    "        \"inventory\": \"mcp://business/inventory\",\n",
    "        \"products\": \"mcp://business/inventory\"\n",
    "    }\n",
    "    \n",
    "    uri = uri_map.get(resource_name.lower())\n",
    "    if not uri:\n",
    "        return json.dumps({\"error\": f\"Resource '{resource_name}' not found\"})\n",
    "        \n",
    "    return business_mcp.read_resource(uri)\n",
    "\n",
    "@tool\n",
    "def mcp_query_analytics(metric: str, period: str = \"month\") -> str:\n",
    "    \"\"\"\n",
    "    Query business analytics through MCP server.\n",
    "    \n",
    "    Args:\n",
    "        metric: The metric to query (sales, users, revenue)\n",
    "        period: Time period for the metric (day, week, month, year)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with analytics data\n",
    "    \"\"\"\n",
    "    return business_mcp.call_tool(\"query_analytics\", {\n",
    "        \"metric\": metric,\n",
    "        \"period\": period\n",
    "    })\n",
    "\n",
    "@tool  \n",
    "def mcp_send_notification(recipient: str, message: str, priority: str = \"medium\") -> str:\n",
    "    \"\"\"\n",
    "    Send notifications through MCP server.\n",
    "    \n",
    "    Args:\n",
    "        recipient: Who to send the notification to\n",
    "        message: The notification message\n",
    "        priority: Priority level (low, medium, high)\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with delivery confirmation\n",
    "    \"\"\"\n",
    "    return business_mcp.call_tool(\"send_notification\", {\n",
    "        \"recipient\": recipient,\n",
    "        \"message\": message,\n",
    "        \"priority\": priority\n",
    "    })\n",
    "\n",
    "# Create MCP-enabled tools list\n",
    "mcp_tools = [mcp_read_resource, mcp_query_analytics, mcp_send_notification]\n",
    "\n",
    "# Create an agent that can use MCP tools\n",
    "mcp_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.2,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "mcp_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a business intelligence assistant with access to company systems through MCP.\n",
    "    \n",
    "    Available MCP resources:\n",
    "    - customer_db: Customer information and account details\n",
    "    - inventory: Product inventory and stock levels\n",
    "    \n",
    "    Available MCP tools:\n",
    "    - mcp_query_analytics: Get business metrics and analytics\n",
    "    - mcp_send_notification: Send notifications to users or systems\n",
    "    - mcp_read_resource: Read data from company databases and systems\n",
    "    \n",
    "    Use these tools to provide comprehensive business insights and take actions when requested.\n",
    "    Always format data nicely and explain what you're doing.\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "mcp_agent = create_tool_calling_agent(mcp_llm, mcp_tools, mcp_prompt)\n",
    "mcp_executor = AgentExecutor(\n",
    "    agent=mcp_agent,\n",
    "    tools=mcp_tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"=== MCP-Enabled Agent Created ===\")\n",
    "print(\"Agent ready with MCP server integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the MCP-enabled agent with business scenarios\n",
    "\n",
    "print(\"=== Test 1: Customer Data Analysis ===\")\n",
    "customer_analysis = mcp_executor.invoke({\n",
    "    \"input\": \"Can you analyze our customer data? I want to see the customer information and understand our customer tiers.\"\n",
    "})\n",
    "print(\"Response:\", customer_analysis['output'])\n",
    "\n",
    "print(\"\\n=== Test 2: Business Analytics ===\")\n",
    "analytics_query = mcp_executor.invoke({\n",
    "    \"input\": \"What were our sales metrics for this month? Also check user metrics.\"\n",
    "})\n",
    "print(\"Response:\", analytics_query['output'])\n",
    "\n",
    "print(\"\\n=== Test 3: Inventory Management ===\") \n",
    "inventory_check = mcp_executor.invoke({\n",
    "    \"input\": \"Check our current inventory levels and identify any products that might need restocking.\"\n",
    "})\n",
    "print(\"Response:\", inventory_check['output'])\n",
    "\n",
    "print(\"\\n=== Test 4: Complex Business Workflow ===\")\n",
    "complex_workflow = mcp_executor.invoke({\n",
    "    \"input\": \"\"\"I need a comprehensive business report:\n",
    "    1. Check our customer database for gold tier customers\n",
    "    2. Get our current sales metrics\n",
    "    3. Review inventory levels\n",
    "    4. If sales are good and we have low inventory, send a notification to 'inventory-team@company.com' about restocking\n",
    "    \n",
    "    Please provide a summary with actionable insights.\"\"\"\n",
    "})\n",
    "print(\"Response:\", complex_workflow['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56c6e2",
   "metadata": {},
   "source": [
    "The examples above demonstrate the power of tools in transforming language models into capable agents. We've seen how **built-in tools** provide immediate capabilities with minimal setup, **explicit tools** offer complete customization for your specific needs, and **MCP tools** enable standardized integration with complex systems while maintaining security and scalability.\n",
    "\n",
    "The key insight is that tools are what bridge the gap between language model intelligence and real-world utility. Without tools, even the most sophisticated language model is limited to generating text based on its training data. With tools, agents become active participants in your business processes, capable of querying databases, performing calculations, calling APIs, and taking actions in response to user needs.\n",
    "\n",
    "As we design agentic systems, the choice between different tool types depends on your specific requirements:\n",
    "- Use **built-in tools** when the model provider offers functionality that meets your needs\n",
    "- Create **explicit tools** when you need custom integration with your specific systems  \n",
    "- Implement **MCP tools** when you need standardized, scalable integrations across multiple AI applications\n",
    "\n",
    "Now that our agents can take actions in the world through tools, we need to ensure they can maintain context and remember information across interactions. This is where memory and context management become crucial for building agents that can handle complex, multi-step workflows and maintain coherent conversations over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0edd85",
   "metadata": {},
   "source": [
    "### Context Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b3a57",
   "metadata": {},
   "source": [
    "<img src=\"https://substackcdn.com/image/fetch/$s_!AyLS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0e3c002-0841-4d5f-9171-3eb63c321824_1600x1224.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f12727",
   "metadata": {},
   "source": [
    "##### LangChain ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7832c6b",
   "metadata": {},
   "source": [
    "##### LangChain ConversationSummaryMemory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1b74d",
   "metadata": {},
   "source": [
    "##### LangChain ConversationBufferWindowMemory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9966adc",
   "metadata": {},
   "source": [
    "##### LangChain ConversationTokenBufferMemory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b91eec",
   "metadata": {},
   "source": [
    "##### LangGraph MemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a3b30",
   "metadata": {},
   "source": [
    "##### LangGraph MessagesState\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298933fa",
   "metadata": {},
   "source": [
    "##### LlamaIndex ChatMemoryBuffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b69c7f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### LlamaIndex VectorMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729477c1",
   "metadata": {},
   "source": [
    "#### Skills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beac902",
   "metadata": {},
   "source": [
    "### Workflows and Chains\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd982d2",
   "metadata": {},
   "source": [
    "##### Parallelization Workflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e6ba0",
   "metadata": {},
   "source": [
    "##### LangGraph Parallel Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f939acc",
   "metadata": {},
   "source": [
    "##### LangChain RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e371d",
   "metadata": {},
   "source": [
    "##### LangGraph Multi-Agent Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1de84",
   "metadata": {},
   "source": [
    "##### LangChain Agent Executors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5567e2",
   "metadata": {},
   "source": [
    "##### LlamaIndex AgentRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd518b",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e3e6c",
   "metadata": {},
   "source": [
    "### But Why RAG?\n",
    "\n",
    "Talk about LLM system in general, while introducing agents, where those workflows lack the limit of llms in context and actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc169c2",
   "metadata": {},
   "source": [
    "### Finding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a060c",
   "metadata": {},
   "source": [
    "#### Webscraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c3655c",
   "metadata": {},
   "source": [
    "##### LangChain WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d21253",
   "metadata": {},
   "source": [
    "##### LangChain AsyncHtmlLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76a4f4",
   "metadata": {},
   "source": [
    "##### LangChain SitemapLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016c6e8",
   "metadata": {},
   "source": [
    "##### LangChain PlaywrightURLLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19028a8c",
   "metadata": {},
   "source": [
    "##### LlamaIndex SimpleWebPageReader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326287d8",
   "metadata": {},
   "source": [
    "\n",
    "##### LlamaIndex BeautifulSoupWebReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d7a17",
   "metadata": {},
   "source": [
    "#### Document Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc20e9",
   "metadata": {},
   "source": [
    "##### LangChain PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb7df0",
   "metadata": {},
   "source": [
    "##### LangChain UnstructuredFileLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af53d8",
   "metadata": {},
   "source": [
    "##### LangChain CSVLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af499259",
   "metadata": {},
   "source": [
    "##### LangChain JSONLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70654f7e",
   "metadata": {},
   "source": [
    "##### LlamaIndex SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a64221",
   "metadata": {},
   "source": [
    "##### LlamaIndex PDFReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc25e03",
   "metadata": {},
   "source": [
    "### Preprocessing the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbf6bd",
   "metadata": {},
   "source": [
    "#### Splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f88889",
   "metadata": {},
   "source": [
    "##### LangChain RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a690a5",
   "metadata": {},
   "source": [
    "##### LangChain TokenTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f31dec",
   "metadata": {},
   "source": [
    "##### LangChain MarkdownHeaderTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20168248",
   "metadata": {},
   "source": [
    "##### LangChain PythonCodeTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0bcfd",
   "metadata": {},
   "source": [
    "##### LlamaIndex SentenceSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4dd95",
   "metadata": {},
   "source": [
    "##### LlamaIndex SemanticSplitterNodeParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32531064",
   "metadata": {},
   "source": [
    "##### LlamaIndex HierarchicalNodeParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfbca2",
   "metadata": {},
   "source": [
    "#### Chunking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8df09",
   "metadata": {},
   "source": [
    "##### LangChain SemanticChunker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d5275",
   "metadata": {},
   "source": [
    "##### LangChain ParentDocumentRetriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7efeb",
   "metadata": {},
   "source": [
    "##### LlamaIndex SimpleNodeParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b604a",
   "metadata": {},
   "source": [
    "##### LlamaIndex SentenceWindowNodeParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d351c",
   "metadata": {},
   "source": [
    "#### Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324ddcb",
   "metadata": {},
   "source": [
    "##### LangChain OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab8dda",
   "metadata": {},
   "source": [
    "##### LangChain HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec7aca",
   "metadata": {},
   "source": [
    "##### LlamaIndex OpenAIEmbedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47ab6a",
   "metadata": {},
   "source": [
    "\n",
    "##### LlamaIndex HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d238e7",
   "metadata": {},
   "source": [
    "### Storing Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477119b6",
   "metadata": {},
   "source": [
    "#### Vector Databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30172c54",
   "metadata": {},
   "source": [
    "##### LangChain Chroma Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a76543",
   "metadata": {},
   "source": [
    "##### LangChain Pinecone Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b117522",
   "metadata": {},
   "source": [
    "##### LangChain FAISS Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d8c52",
   "metadata": {},
   "source": [
    "##### LlamaIndex ChromaVectorStore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a255cc0",
   "metadata": {},
   "source": [
    "\n",
    "##### LlamaIndex PineconeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608dc711",
   "metadata": {},
   "source": [
    "#### Knowledge Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e862dd1",
   "metadata": {},
   "source": [
    "##### LangGraph StateGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78022c",
   "metadata": {},
   "source": [
    "##### LangChain Neo4jGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45991c4f",
   "metadata": {},
   "source": [
    "\n",
    "##### LlamaIndex KnowledgeGraphIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090d616",
   "metadata": {},
   "source": [
    "#### SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553ab93",
   "metadata": {},
   "source": [
    "##### LangChain SQLDatabase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465957c",
   "metadata": {},
   "source": [
    "##### LangChain SQLDatabaseChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154a1a8",
   "metadata": {},
   "source": [
    "\n",
    "##### LlamaIndex SQLStructStoreIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f8555b",
   "metadata": {},
   "source": [
    "### Retrieval Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df26eae",
   "metadata": {},
   "source": [
    "#### Vector search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e03ebd",
   "metadata": {},
   "source": [
    "##### LangChain VectorStoreRetriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668dc4c",
   "metadata": {},
   "source": [
    "##### LangChain MultiVectorRetriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf8b81f",
   "metadata": {},
   "source": [
    "##### LlamaIndex VectorIndexRetriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ecc5a",
   "metadata": {},
   "source": [
    "\n",
    "##### LlamaIndex VectorIndexAutoRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcdc80",
   "metadata": {},
   "source": [
    "#### Tree Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ccf6a",
   "metadata": {},
   "source": [
    "#### Node Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c0bcc",
   "metadata": {},
   "source": [
    "#### Hybrid Search\n",
    "\n",
    "##### LangChain EnsembleRetriever\n",
    "##### LangChain BM25Retriever\n",
    "##### LlamaIndex QueryFusionRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9945c",
   "metadata": {},
   "source": [
    "##### LangChain ConditionalEdge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c3f5c5",
   "metadata": {},
   "source": [
    "##### LangGraph Router Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99707a7f",
   "metadata": {},
   "source": [
    "##### LlamaIndex RouterQueryEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbce248",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2bacb9",
   "metadata": {},
   "source": [
    "#### Faithfulness & Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b7c07",
   "metadata": {},
   "source": [
    "#### RAGAS (RAG Assessment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d187128",
   "metadata": {},
   "source": [
    "##### LangSmith + RAGAS Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d6e4",
   "metadata": {},
   "source": [
    "##### LangChain Evaluation Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514c762",
   "metadata": {},
   "source": [
    "#### TruLens RAG Triad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2ef4c",
   "metadata": {},
   "source": [
    "#### Multi-Agent Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315a255",
   "metadata": {},
   "source": [
    "#### Advanced Agentic Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2815e8c",
   "metadata": {},
   "source": [
    "#### Human Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e2760",
   "metadata": {},
   "source": [
    "#### LLM-as-Judge\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdcbe94",
   "metadata": {},
   "source": [
    "##### LangSmith Tracing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a7f4c",
   "metadata": {},
   "source": [
    "##### LangSmith Evaluation Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb866f",
   "metadata": {},
   "source": [
    "##### LangSmith Custom Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f82ea2",
   "metadata": {},
   "source": [
    "## A Complete Agentic System\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a72785",
   "metadata": {},
   "source": [
    "##### LangGraph Agent Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9799f18",
   "metadata": {},
   "source": [
    "##### LangChain Agent Types (ReAct, Plan-and-Execute)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31925586",
   "metadata": {},
   "source": [
    "##### LangSmith Agent Monitoring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5da5a",
   "metadata": {},
   "source": [
    "##### LlamaIndex Multi-Agent Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11448f82",
   "metadata": {},
   "source": [
    "## Limitations & Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927ba15",
   "metadata": {},
   "source": [
    "#### RAPTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a3d4e",
   "metadata": {},
   "source": [
    "#### Self-RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8d098",
   "metadata": {},
   "source": [
    "#### CRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d56e81",
   "metadata": {},
   "source": [
    "#### Adaptive RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adba2b0",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6403629",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
